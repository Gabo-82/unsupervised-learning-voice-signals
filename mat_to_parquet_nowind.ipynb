{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "167d0dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from typing import List, Optional\n",
    "import scipy.io\n",
    "\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ util ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def matlab_datenum_to_datetime(dn: float) -> datetime.datetime:\n",
    "    \"\"\"Convierte un datenum MATLAB a datetime; si dn es NaN ‚Üí NaT.\"\"\"\n",
    "    if np.isnan(dn):\n",
    "        return pd.NaT\n",
    "    frac = dn % 1\n",
    "    return (datetime.datetime.fromordinal(int(dn))\n",
    "            + datetime.timedelta(days=frac) - datetime.timedelta(days=366))\n",
    "\n",
    "def mat_to_parquet(file_path: str,\n",
    "                   file_path_ibif: str,\n",
    "                   output_folder: str = '.',\n",
    "                   valid_keys: Optional[List[str]] = None,\n",
    "                   ibif_keys: Optional[List[str]] = None,\n",
    "                   week: str = \"W1\"):\n",
    "    \"\"\"\n",
    "    Une archivo de se√±ales (*.mat) + archivo IBIF separado.\n",
    "    Conserva solo muestras en las que:\n",
    "        voicedRMS == 1  Y  breathGroup contiene ‚â•15 unos consecutivos.\n",
    "    Descarta filas con NaN en timestamps (solo si el .mat tra√≠a timestamps).\n",
    "    Guarda resultado a .parquet.\n",
    "    \"\"\"\n",
    "    if valid_keys is None:\n",
    "        raise ValueError(\"Debes proporcionar una lista de valid_keys.\")\n",
    "    if ibif_keys is None:\n",
    "        ibif_keys = ['acflow', 'mfdr', 'oq', 'naq', 'h1h2', 'voicedRMS']\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ metadatos del nombre ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    base = os.path.basename(file_path).replace('.mat', '')\n",
    "    m = re.match(r'([NP])([FM])(\\d+)_([\\d]{8})', base)\n",
    "    if not m:\n",
    "        raise ValueError(\"Nombre de archivo no v√°lido: \" + base)\n",
    "    stat_tag, gen_tag, sid, date_str = m.groups()\n",
    "    status     = 'Normal' if stat_tag == 'N' else 'Pathological'\n",
    "    subject_id = f\"{stat_tag}{gen_tag}{sid}\"\n",
    "    date_dt    = datetime.datetime.strptime(date_str, \"%Y%m%d\")\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ helper de carga ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    def load_mat(path):\n",
    "        try:\n",
    "            with h5py.File(path, 'r') as f:\n",
    "                return {k: np.array(f[k]) for k in f.keys()}\n",
    "        except OSError:\n",
    "            return scipy.io.loadmat(path)\n",
    "\n",
    "    mat_data  = load_mat(file_path)\n",
    "    ibif_data = load_mat(file_path_ibif)\n",
    "\n",
    "    # -------- voicedRMS --------\n",
    "    if 'voicedRMS' not in ibif_data:\n",
    "        raise KeyError(f\"{file_path_ibif} no contiene 'voicedRMS'\")\n",
    "    voiced_mask = ibif_data['voicedRMS'].flatten().astype(bool)\n",
    "\n",
    "    # -------- breathGroup ------ (puede estar en archivo principal o IBIF)\n",
    "    if 'breathGroup' in mat_data:\n",
    "        breath = mat_data['breathGroup'].flatten().astype(bool)\n",
    "    elif 'breathGroup' in ibif_data:\n",
    "        breath = ibif_data['breathGroup'].flatten().astype(bool)\n",
    "    else:\n",
    "        raise KeyError(\"'breathGroup' no encontrado en archivos\")\n",
    "\n",
    "    if len(breath) != len(voiced_mask):\n",
    "        raise ValueError(\"'breathGroup' y 'voicedRMS' tienen longitudes distintas\")\n",
    "\n",
    "    # ‚ñ∫ breath_long: secuencias de 1 con longitud ‚â• 15\n",
    "    breath_long = np.zeros_like(breath, dtype=bool)\n",
    "    i = 0\n",
    "    n = len(breath)\n",
    "    while i < n:\n",
    "        if breath[i]:\n",
    "            j = i\n",
    "            while j < n and breath[j]:\n",
    "                j += 1\n",
    "            if j - i >= 30:\n",
    "                breath_long[i:j] = True\n",
    "            i = j\n",
    "        else:\n",
    "            i += 1\n",
    "\n",
    "    # m√°scara final\n",
    "    use_mask = voiced_mask & breath_long\n",
    "    if not use_mask.any():\n",
    "        print(f\"‚ö†Ô∏è {base}: ninguna muestra cumple voiced & breathGroup‚â•15\")\n",
    "        return\n",
    "\n",
    "    # -------- timestamps --------\n",
    "    has_ts = 'timestamps' in mat_data\n",
    "    if has_ts:\n",
    "        ts_raw = mat_data['timestamps'].flatten()[use_mask]\n",
    "        ts_dt  = np.array([matlab_datenum_to_datetime(x) for x in ts_raw])\n",
    "        ts_sec = np.array([(t - date_dt).total_seconds() if t is not pd.NaT else np.nan\n",
    "                           for t in ts_dt])\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è archivo sin 'timestamps'; se usar√°n NaN/NaT.\")\n",
    "        ts_dt  = np.full(use_mask.sum(), pd.NaT)\n",
    "        ts_sec = np.full(use_mask.sum(), np.nan)\n",
    "\n",
    "    # -------- DataFrame base ----\n",
    "    df = pd.DataFrame({\n",
    "        'ts'        : ts_dt,\n",
    "        'ts_sec'    : ts_sec,\n",
    "        'subject_id': subject_id,\n",
    "        'status'    : 'Control' if status == 'Normal' else 'Patient',\n",
    "        'week'      : ('Control' if status == 'Normal'\n",
    "                       else 'Pre' if week == 'W1' else 'Post'),\n",
    "        'date'      : date_str\n",
    "    })\n",
    "\n",
    "    # -------- agregar features principales -----\n",
    "    for k in valid_keys:\n",
    "        if k in mat_data and k != 'timestamps':\n",
    "            df[k] = mat_data[k].flatten()[use_mask]\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è '{k}' no encontrado en {base}\")\n",
    "\n",
    "    # -------- agregar features IBIF -------------\n",
    "    for k in ibif_keys:\n",
    "        if k in ibif_data:\n",
    "            df[k] = ibif_data[k].flatten()[use_mask]\n",
    "        else:\n",
    "            print(f\"‚ö†Ô∏è '{k}' no encontrado en IBIF\")\n",
    "\n",
    "    # -------- eliminar NaN en ts si hay timestamps ----\n",
    "    if has_ts:\n",
    "        n0 = len(df)\n",
    "        df = df[~df['ts'].isna()]\n",
    "        if len(df) < n0:\n",
    "            print(f\"üîç Eliminadas {n0-len(df)} filas con NaN en timestamps.\")\n",
    "\n",
    "    if df.empty:\n",
    "        print(\"‚ö†Ô∏è No quedan filas v√°lidas; archivo omitido.\")\n",
    "        return\n",
    "\n",
    "    # -------- guardar parquet -------------\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    out_path = os.path.join(output_folder, f\"{subject_id}_{date_str}.parquet\")\n",
    "    df.to_parquet(out_path, index=False)\n",
    "    print(f\"üì¶ Guardado ‚Üí {out_path}\")\n",
    "\n",
    "# ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ funci√≥n principal ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "def mat_to_parquet_new(file_path: str,\n",
    "                       output_folder: str = '.',\n",
    "                       valid_keys: Optional[List[str]] = None,\n",
    "                       ibif_keys: Optional[List[str]] = None,\n",
    "                       week: str = \"W1\"):\n",
    "\n",
    "    if valid_keys is None:\n",
    "        raise ValueError(\"Debes proporcionar una lista de valid_keys.\")\n",
    "    if ibif_keys is None:\n",
    "        ibif_keys = ['acflow', 'mfdr', 'oq', 'naq', 'h1h2', 'voicedRMS']\n",
    "\n",
    "    # ----------- metadatos ----------- #\n",
    "    base = os.path.basename(file_path).replace('.mat', '')\n",
    "    m = re.match(r'([NP])([FM])(\\d+)_([\\d]{8})', base)\n",
    "    if not m:\n",
    "        raise ValueError(\"Nombre de archivo no v√°lido: \" + base)\n",
    "    status_tag, gender_tag, sid, date_str = m.groups()\n",
    "    status     = 'Normal' if status_tag == 'N' else 'Pathological'\n",
    "    subject_id = f\"{status_tag}{gender_tag}{sid}\"\n",
    "    date_dt    = datetime.datetime.strptime(date_str, \"%Y%m%d\")\n",
    "\n",
    "    # ----------- lectura HDF5 --------- #\n",
    "    with h5py.File(file_path, 'r') as f:\n",
    "        print(f\"‚úÖ {file_path} (HDF5)\")\n",
    "\n",
    "        # --- voiced mask (IBIF) --- #\n",
    "        ibif = f['IBIF']\n",
    "        voiced_mask = np.array(ibif['voicedRMS']).flatten().astype(bool)\n",
    "\n",
    "        # --- breathGroup --- #\n",
    "        if 'breathGroup' in f:\n",
    "            breath = np.array(f['breathGroup']).flatten().astype(bool)\n",
    "        elif 'breathGroup' in ibif:\n",
    "            breath = np.array(ibif['breathGroup']).flatten().astype(bool)\n",
    "        else:\n",
    "            raise KeyError(\"'breathGroup' no encontrado ni en ra√≠z ni en 'IBIF'\")\n",
    "\n",
    "        if len(breath) != len(voiced_mask):\n",
    "            raise ValueError(\"'breathGroup' y 'voicedRMS' tienen longitudes distintas\")\n",
    "\n",
    "        # ‚ñ∫ generar m√°scara breath_long (secuencias de 1 de longitud ‚â• 15)\n",
    "        breath_long = np.zeros_like(breath, dtype=bool)\n",
    "        i = 0\n",
    "        n = len(breath)\n",
    "        while i < n:\n",
    "            if breath[i]:\n",
    "                j = i\n",
    "                while j < n and breath[j]:\n",
    "                    j += 1\n",
    "                if j - i >= 30:\n",
    "                    breath_long[i:j] = True\n",
    "                i = j\n",
    "            else:\n",
    "                i += 1\n",
    "\n",
    "        # m√°scara definitiva: voiced & breath_long\n",
    "        use_mask = voiced_mask & breath_long\n",
    "        if not use_mask.any():\n",
    "            print(\"‚ö†Ô∏è Ninguna muestra cumple voiced + breathGroup‚â•15; archivo omitido.\")\n",
    "            return\n",
    "\n",
    "        # --- timestamps --- #\n",
    "        has_ts = \"timestamps\" in f\n",
    "        if has_ts:\n",
    "            ts_raw = np.array(f[\"timestamps\"]).flatten()\n",
    "            ts_raw = ts_raw[use_mask]                      # filtrar ya aqu√≠\n",
    "            ts_dt  = np.array([matlab_datenum_to_datetime(x) for x in ts_raw])\n",
    "            ts_sec = np.array([(t - date_dt).total_seconds()\n",
    "                               if t is not pd.NaT else np.nan\n",
    "                               for t in ts_dt])\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è NO hay 'timestamps'; se registrar√°n NaN/NaT.\")\n",
    "            ts_dt  = np.full(use_mask.sum(), pd.NaT)\n",
    "            ts_sec = np.full(use_mask.sum(), np.nan)\n",
    "\n",
    "        # ----------- DataFrame base --------- #\n",
    "        df = pd.DataFrame({\n",
    "            'ts'        : ts_dt,\n",
    "            'ts_sec'    : ts_sec,\n",
    "            'subject_id': subject_id,\n",
    "            'status'    : 'Control' if status == 'Normal' else 'Patient',\n",
    "            'week'      : ('Control' if status == 'Normal'\n",
    "                           else 'Pre' if week == 'W1' else 'Post'),\n",
    "            'date'      : date_str\n",
    "        })\n",
    "\n",
    "        # --------- a√±adir se√±ales planas ------- #\n",
    "        for k in valid_keys:\n",
    "            if k in f and k != 'timestamps':\n",
    "                df[k] = np.array(f[k]).flatten()[use_mask]\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è '{k}' no encontrado en {base}\")\n",
    "\n",
    "        # --------- a√±adir se√±ales IBIF --------- #\n",
    "        for k in ibif_keys:\n",
    "            if k in ibif:\n",
    "                df[k] = np.array(ibif[k]).flatten()[use_mask]\n",
    "            else:\n",
    "                print(f\"‚ö†Ô∏è '{k}' no encontrado en IBIF\")\n",
    "\n",
    "    # --- descartar filas con NaT si hab√≠a timestamps reales --- #\n",
    "    if has_ts:\n",
    "        n0 = len(df)\n",
    "        df = df[~df['ts'].isna()]\n",
    "        if len(df) < n0:\n",
    "            print(f\"üîç Eliminadas {n0-len(df)} filas con NaN en timestamps.\")\n",
    "\n",
    "    if df.empty:\n",
    "        print(\"‚ö†Ô∏è No quedan filas v√°lidas; archivo omitido.\")\n",
    "        return\n",
    "\n",
    "    # ----------- guardar ---------------------- #\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    out_path = os.path.join(output_folder, f\"{subject_id}_{date_str}.parquet\")\n",
    "    df.to_parquet(out_path, index=False)\n",
    "    print(f\"üì¶ Guardado ‚Üí {out_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1da14dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_keys = ['cppall', 'zcrall', 'normpeakall', 'spectralTiltall', 'LHratioall', 'H1H2all', 'periodicity', 'level', 'freq', 'dBcms2', 'cppall_2048']\n",
    "ibif_keys=['acflow', 'mfdr', 'oq', 'naq', 'h1h2', 'voicedRMS']\n",
    "\n",
    "carpeta = \"data/NF063/W1\"\n",
    "output_folder = \"parquets/no_wind/NF063\"\n",
    "\n",
    "# Listar todos los archivos .mat y filtrar los que NO son IBIF\n",
    "archivos_base = sorted([\n",
    "    f for f in os.listdir(carpeta)\n",
    "    if f.endswith(\".mat\") and \"_IBIF\" not in f\n",
    "])\n",
    "\n",
    "for base_file in archivos_base:\n",
    "    # Construir ruta completa\n",
    "    file_path = os.path.join(carpeta, base_file)\n",
    "\n",
    "    # Crear nombre de archivo IBIF\n",
    "    name_no_ext = base_file.replace(\".mat\", \"\")\n",
    "    ibif_name = f\"{name_no_ext}_01_IBIF.mat\"\n",
    "    file_path_ibif = os.path.join(carpeta, ibif_name)\n",
    "\n",
    "    # Verificar que exista el archivo IBIF\n",
    "    if not os.path.exists(file_path_ibif):\n",
    "        print(f\"‚ùå No se encontr√≥ IBIF para {base_file}\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # Llamar a tu funci√≥n\n",
    "        mat_to_parquet(\n",
    "            file_path=file_path,\n",
    "            file_path_ibif=file_path_ibif,\n",
    "            output_folder=output_folder,\n",
    "            valid_keys=valid_keys,\n",
    "            ibif_keys=ibif_keys,\n",
    "            week=\"W1\",  # puedes cambiar esto si detectas W2 por nombre\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error procesando {base_file}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cbe673b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ data\\NF140\\W1\\NF140_20150101.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\NF140\\NF140_20150101.parquet\n",
      "‚úÖ data\\NF140\\W1\\NF140_20150102.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\NF140\\NF140_20150102.parquet\n",
      "‚úÖ data\\NF140\\W1\\NF140_20150103.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\NF140\\NF140_20150103.parquet\n",
      "‚úÖ data\\NF140\\W1\\NF140_20150105.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\NF140\\NF140_20150105.parquet\n",
      "‚úÖ data\\NF140\\W1\\NF140_20150106.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\NF140\\NF140_20150106.parquet\n",
      "‚úÖ data\\NF140\\W1\\NF140_20150107.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\NF140\\NF140_20150107.parquet\n",
      "‚úÖ data\\NF140\\W1\\NF140_20150108.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\NF140\\NF140_20150108.parquet\n",
      "‚úÖ data\\PF140\\W1\\PF140_20150101.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF140\\PF140_20150101.parquet\n",
      "‚úÖ data\\PF140\\W1\\PF140_20150102.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF140\\PF140_20150102.parquet\n",
      "‚úÖ data\\PF140\\W1\\PF140_20150103.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF140\\PF140_20150103.parquet\n",
      "‚úÖ data\\PF140\\W1\\PF140_20150104.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF140\\PF140_20150104.parquet\n",
      "‚úÖ data\\PF140\\W1\\PF140_20150105.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF140\\PF140_20150105.parquet\n",
      "‚úÖ data\\PF140\\W1\\PF140_20150106.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF140\\PF140_20150106.parquet\n",
      "‚úÖ data\\PF140\\W1\\PF140_20150107.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF140\\PF140_20150107.parquet\n",
      "‚úÖ data\\PF140\\W2\\PF140_20150513.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF140\\PF140_20150513.parquet\n",
      "‚úÖ data\\PF140\\W2\\PF140_20150514.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF140\\PF140_20150514.parquet\n",
      "‚úÖ data\\PF140\\W2\\PF140_20150515.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF140\\PF140_20150515.parquet\n",
      "‚úÖ data\\PF140\\W2\\PF140_20150516.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF140\\PF140_20150516.parquet\n",
      "‚úÖ data\\PF140\\W2\\PF140_20150517.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF140\\PF140_20150517.parquet\n",
      "‚úÖ data\\PF140\\W2\\PF140_20150518.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF140\\PF140_20150518.parquet\n",
      "‚úÖ data\\PF140\\W2\\PF140_20150519.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF140\\PF140_20150519.parquet\n",
      "‚úÖ data\\NF129\\W1\\NF129_20140101.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\NF129\\NF129_20140101.parquet\n",
      "‚úÖ data\\NF129\\W1\\NF129_20140102.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\NF129\\NF129_20140102.parquet\n",
      "‚úÖ data\\NF129\\W1\\NF129_20140103.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\NF129\\NF129_20140103.parquet\n",
      "‚úÖ data\\NF129\\W1\\NF129_20140104.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\NF129\\NF129_20140104.parquet\n",
      "‚úÖ data\\NF129\\W1\\NF129_20140105.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\NF129\\NF129_20140105.parquet\n",
      "‚úÖ data\\NF129\\W1\\NF129_20140108.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\NF129\\NF129_20140108.parquet\n",
      "‚úÖ data\\NF129\\W1\\NF129_20140109.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\NF129\\NF129_20140109.parquet\n",
      "‚úÖ data\\PF129\\W1\\PF129_20140101.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF129\\PF129_20140101.parquet\n",
      "‚úÖ data\\PF129\\W1\\PF129_20140102.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF129\\PF129_20140102.parquet\n",
      "‚úÖ data\\PF129\\W1\\PF129_20140103.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF129\\PF129_20140103.parquet\n",
      "‚úÖ data\\PF129\\W1\\PF129_20140104.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF129\\PF129_20140104.parquet\n",
      "‚úÖ data\\PF129\\W1\\PF129_20140105.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF129\\PF129_20140105.parquet\n",
      "‚úÖ data\\PF129\\W1\\PF129_20140106.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF129\\PF129_20140106.parquet\n",
      "‚úÖ data\\PF129\\W1\\PF129_20140108.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF129\\PF129_20140108.parquet\n",
      "‚úÖ data\\PF129\\W2\\PF129_20140302.mat (HDF5)\n",
      "‚ùå Error al procesar data\\PF129\\W2\\PF129_20140302.mat: \"Unable to synchronously open object (object 'IBIF' doesn't exist)\"\n",
      "‚úÖ data\\PF129\\W2\\PF129_20140303.mat (HDF5)\n",
      "‚ùå Error al procesar data\\PF129\\W2\\PF129_20140303.mat: \"Unable to synchronously open object (object 'IBIF' doesn't exist)\"\n",
      "‚úÖ data\\PF129\\W2\\PF129_20140304.mat (HDF5)\n",
      "‚ùå Error al procesar data\\PF129\\W2\\PF129_20140304.mat: \"Unable to synchronously open object (object 'IBIF' doesn't exist)\"\n",
      "‚úÖ data\\PF129\\W2\\PF129_20140305.mat (HDF5)\n",
      "‚ùå Error al procesar data\\PF129\\W2\\PF129_20140305.mat: \"Unable to synchronously open object (object 'IBIF' doesn't exist)\"\n",
      "‚úÖ data\\PF129\\W2\\PF129_20140307.mat (HDF5)\n",
      "‚ùå Error al procesar data\\PF129\\W2\\PF129_20140307.mat: \"Unable to synchronously open object (object 'IBIF' doesn't exist)\"\n",
      "‚úÖ data\\PF129\\W2\\PF129_20140308.mat (HDF5)\n",
      "‚ùå Error al procesar data\\PF129\\W2\\PF129_20140308.mat: \"Unable to synchronously open object (object 'IBIF' doesn't exist)\"\n",
      "‚úÖ data\\PF129\\W2\\PF129_20140309.mat (HDF5)\n",
      "‚ùå Error al procesar data\\PF129\\W2\\PF129_20140309.mat: \"Unable to synchronously open object (object 'IBIF' doesn't exist)\"\n",
      "‚úÖ data\\NF109\\W1\\NF109_20140101.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\NF109\\NF109_20140101.parquet\n",
      "‚úÖ data\\NF109\\W1\\NF109_20140102.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\NF109\\NF109_20140102.parquet\n",
      "‚úÖ data\\NF109\\W1\\NF109_20140103.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\NF109\\NF109_20140103.parquet\n",
      "‚úÖ data\\NF109\\W1\\NF109_20140104.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\NF109\\NF109_20140104.parquet\n",
      "‚úÖ data\\NF109\\W1\\NF109_20140105.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\NF109\\NF109_20140105.parquet\n",
      "‚úÖ data\\NF109\\W1\\NF109_20140106.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\NF109\\NF109_20140106.parquet\n",
      "‚úÖ data\\NF109\\W1\\NF109_20140107.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\NF109\\NF109_20140107.parquet\n",
      "‚úÖ data\\PF109\\W1\\PF109_20140101.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF109\\PF109_20140101.parquet\n",
      "‚úÖ data\\PF109\\W1\\PF109_20140102.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF109\\PF109_20140102.parquet\n",
      "‚úÖ data\\PF109\\W1\\PF109_20140103.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF109\\PF109_20140103.parquet\n",
      "‚úÖ data\\PF109\\W1\\PF109_20140104.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF109\\PF109_20140104.parquet\n",
      "‚úÖ data\\PF109\\W1\\PF109_20140105.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF109\\PF109_20140105.parquet\n",
      "‚úÖ data\\PF109\\W1\\PF109_20140106.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF109\\PF109_20140106.parquet\n",
      "‚úÖ data\\PF109\\W1\\PF109_20140107.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF109\\PF109_20140107.parquet\n",
      "‚úÖ data\\PF109\\W2\\PF109_20140630.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF109\\PF109_20140630.parquet\n",
      "‚úÖ data\\PF109\\W2\\PF109_20140701.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF109\\PF109_20140701.parquet\n",
      "‚úÖ data\\PF109\\W2\\PF109_20140702.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF109\\PF109_20140702.parquet\n",
      "‚úÖ data\\PF109\\W2\\PF109_20140703.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF109\\PF109_20140703.parquet\n",
      "‚úÖ data\\PF109\\W2\\PF109_20140704.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF109\\PF109_20140704.parquet\n",
      "‚úÖ data\\PF109\\W2\\PF109_20140705.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF109\\PF109_20140705.parquet\n",
      "‚úÖ data\\PF109\\W2\\PF109_20140706.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF109\\PF109_20140706.parquet\n",
      "‚úÖ data\\NF022\\W1\\NF022_20120101.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\NF022\\NF022_20120101.parquet\n",
      "‚úÖ data\\NF022\\W1\\NF022_20120102.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\NF022\\NF022_20120102.parquet\n",
      "‚úÖ data\\NF022\\W1\\NF022_20120105.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\NF022\\NF022_20120105.parquet\n",
      "‚úÖ data\\NF022\\W1\\NF022_20120106.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\NF022\\NF022_20120106.parquet\n",
      "‚úÖ data\\NF022\\W1\\NF022_20120107.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\NF022\\NF022_20120107.parquet\n",
      "‚úÖ data\\NF022\\W1\\NF022_20120108.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\NF022\\NF022_20120108.parquet\n",
      "‚úÖ data\\NF022\\W1\\NF022_20120109.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\NF022\\NF022_20120109.parquet\n",
      "‚úÖ data\\PF022\\W1\\PF022_20120101.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF022\\PF022_20120101.parquet\n",
      "‚úÖ data\\PF022\\W1\\PF022_20120102.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF022\\PF022_20120102.parquet\n",
      "‚úÖ data\\PF022\\W1\\PF022_20120103.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF022\\PF022_20120103.parquet\n",
      "‚úÖ data\\PF022\\W1\\PF022_20120104.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF022\\PF022_20120104.parquet\n",
      "‚úÖ data\\PF022\\W1\\PF022_20120105.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF022\\PF022_20120105.parquet\n",
      "‚úÖ data\\PF022\\W1\\PF022_20120106.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF022\\PF022_20120106.parquet\n",
      "‚úÖ data\\PF022\\W1\\PF022_20120107.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF022\\PF022_20120107.parquet\n",
      "‚úÖ data\\PF022\\W2\\PF022_20120216.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF022\\PF022_20120216.parquet\n",
      "‚úÖ data\\PF022\\W2\\PF022_20120217.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF022\\PF022_20120217.parquet\n",
      "‚úÖ data\\PF022\\W2\\PF022_20120218.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF022\\PF022_20120218.parquet\n",
      "‚úÖ data\\PF022\\W2\\PF022_20120219.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF022\\PF022_20120219.parquet\n",
      "‚úÖ data\\PF022\\W2\\PF022_20120220.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF022\\PF022_20120220.parquet\n",
      "‚úÖ data\\PF022\\W2\\PF022_20120221.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF022\\PF022_20120221.parquet\n",
      "‚úÖ data\\PF022\\W2\\PF022_20120222.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF022\\PF022_20120222.parquet\n",
      "‚úÖ data\\NF021\\W1\\NF021_20120101.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\NF021\\NF021_20120101.parquet\n",
      "‚úÖ data\\NF021\\W1\\NF021_20120102.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\NF021\\NF021_20120102.parquet\n",
      "‚úÖ data\\NF021\\W1\\NF021_20120103.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\NF021\\NF021_20120103.parquet\n",
      "‚úÖ data\\NF021\\W1\\NF021_20120104.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\NF021\\NF021_20120104.parquet\n",
      "‚úÖ data\\NF021\\W1\\NF021_20120105.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\NF021\\NF021_20120105.parquet\n",
      "‚úÖ data\\NF021\\W1\\NF021_20120106.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\NF021\\NF021_20120106.parquet\n",
      "‚úÖ data\\NF021\\W1\\NF021_20120113.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\NF021\\NF021_20120113.parquet\n",
      "‚úÖ data\\PF021\\W1\\PF021_20120101.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF021\\PF021_20120101.parquet\n",
      "‚úÖ data\\PF021\\W1\\PF021_20120102.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF021\\PF021_20120102.parquet\n",
      "‚úÖ data\\PF021\\W1\\PF021_20120103.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF021\\PF021_20120103.parquet\n",
      "‚úÖ data\\PF021\\W1\\PF021_20120104.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF021\\PF021_20120104.parquet\n",
      "‚úÖ data\\PF021\\W2\\PF021_20120303.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF021\\PF021_20120303.parquet\n",
      "‚úÖ data\\PF021\\W2\\PF021_20120304.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF021\\PF021_20120304.parquet\n",
      "‚úÖ data\\PF021\\W2\\PF021_20120306.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF021\\PF021_20120306.parquet\n",
      "‚úÖ data\\PF021\\W2\\PF021_20120308.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF021\\PF021_20120308.parquet\n",
      "‚úÖ data\\PF021\\W2\\PF021_20120309.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF021\\PF021_20120309.parquet\n",
      "‚úÖ data\\PF021\\W2\\PF021_20120310.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF021\\PF021_20120310.parquet\n",
      "‚úÖ data\\PF021\\W2\\PF021_20120311.mat (HDF5)\n",
      "üì¶ Guardado ‚Üí parquets/no_wind\\PF021\\PF021_20120311.parquet\n"
     ]
    }
   ],
   "source": [
    "valid_keys = ['cppall', 'zcrall', 'normpeakall', 'spectralTiltall', 'LHratioall', 'H1H2all', 'periodicity', 'level', 'freq', 'dBcms2', 'cppall_2048']\n",
    "ibif_keys=['acflow', 'mfdr', 'oq', 'naq', 'h1h2', 'voicedRMS']\n",
    "\n",
    "sujetos = [\"NF140\", \"PF140\", \"NF129\", \"PF129\", \"NF109\", \"PF109\", \"NF022\", \"PF022\", \"NF021\", \"PF021\"]\n",
    "\n",
    "base_input_dir  = \"data\"\n",
    "base_output_dir = \"parquets/no_wind\"\n",
    "\n",
    "for sujeto in sujetos:\n",
    "    sujeto_path = os.path.join(base_input_dir, sujeto)\n",
    "    week_dirs = [\"W1\"] if sujeto.startswith(\"NF\") else [\"W1\", \"W2\"]\n",
    "\n",
    "    for week in week_dirs:\n",
    "        week_path = os.path.join(sujeto_path, week)\n",
    "        output_folder = os.path.join(base_output_dir, sujeto)\n",
    "\n",
    "        if not os.path.isdir(week_path):\n",
    "            print(f\"‚ö†Ô∏è Carpeta no encontrada: {week_path}\")\n",
    "            continue\n",
    "\n",
    "        for file in sorted(os.listdir(week_path)):\n",
    "            if file.endswith(\".mat\"):\n",
    "                file_path = os.path.join(week_path, file)\n",
    "                try:\n",
    "                    mat_to_parquet_new(\n",
    "                        file_path=file_path,\n",
    "                        output_folder=output_folder,\n",
    "                        valid_keys=valid_keys,\n",
    "                        ibif_keys=ibif_keys,\n",
    "                        week=week  # \"W1\" o \"W2\"\n",
    "                    )\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Error al procesar {file_path}: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
